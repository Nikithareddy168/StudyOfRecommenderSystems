{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import some libraries we'll need\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math as math\n",
    "import scipy.sparse as sps\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_review_data(file_name):\n",
    "    review_data = pd.read_csv(file_name)\n",
    "    print \"Sample Data\"\n",
    "    print \"-----------\"\n",
    "    print review_data.sample(5)\n",
    "    return review_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "eider.env.getUploaded(\"business.csv\", \"/tmp/business.csv\")\n",
    "business_data = pd.read_csv('/tmp/business.csv')\n",
    "business_data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "business_data.set_index('business_id', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_restaurant_data(review_data, business_data):\n",
    "    review_data['city'] = review_data.apply(lambda x: business_data.loc[x['business_id'], 'city'], axis=1)\n",
    "    review_data['cat'] = review_data.apply(lambda x: business_data.loc[x['business_id'], 'categories'], axis=1)\n",
    "    restaurant_reviews = review_data[review_data['cat'].str.contains(\"Restaurants\",na=False)]\n",
    "    return restaurant_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_city_restaurant_data(city, restaurant_reviews):\n",
    "    city_rest_data = restaurant_reviews.loc[review_data['city'] == city]\n",
    "    return city_rest_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_sparse_matrix(df):\n",
    "    users = list(df['user_id'].unique())\n",
    "    rests = list(df['business_id'].unique())\n",
    "    data = df['stars'].tolist()\n",
    "    row = df['user_id'].astype('category', categories=users).cat.codes\n",
    "    col = df['business_id'].astype('category', categories=rests).cat.codes\n",
    "    rating_matrix = csr_matrix((data, (row, col)), shape=(len(users), len(rests)))\n",
    "    return rating_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test(df):\n",
    "    '''Split for train and test data'''\n",
    "    rating_matrix = build_sparse_matrix(df)\n",
    "    train, test = split_rating_matrix(rating_matrix)\n",
    "    num_train = train.shape[0]\n",
    "    num_test = test.shape[0]\n",
    "    \n",
    "    print \"Number of training samples: {}\".format(num_train)\n",
    "    print \"Number of test samples: {}\".format(num_test)\n",
    "    \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sparse_matrix(df):\n",
    "    '''Converts the df into a sparse ratings matrix'''\n",
    "    unique_users = df['user_id'].unique().tolist()\n",
    "    unique_rests = df['business_id'].unique().tolist()\n",
    "    data = df['stars'].tolist()\n",
    "    row = df['user_id'].astype('category', categories=unique_users).cat.codes\n",
    "    col = df['business_id'].astype('category', categories=unique_bus).cat.codes\n",
    "    sparse_matrix = csr_matrix((data, (row, col)), shape=(len(unique_users), len(unique_rests)))\n",
    "    return sparse_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_rating_matrix(rating_matrix, samples = 2):\n",
    "    users, restaurants =  rating_matrix.nonzero()\n",
    "    test = csr_matrix(rating_matrix.shape)\n",
    "    train = rating_matrix.copy()\n",
    "\n",
    "    num_users = rating_matrix.shape[0]\n",
    "    for u in range(num_users):\n",
    "        idx = restaurants[np.where(users == u)]\n",
    "        np.random.shuffle(idx)\n",
    "        test_idx = idx[-samples:]\n",
    "        train_idx = idx[:-samples]\n",
    "        test[u,test_idx] = rating_matrix[u,test_idx]\n",
    "        train[u,test_idx] = 0\n",
    "\n",
    "    data = np.array(train[train.nonzero()])[0]\n",
    "    row = train.nonzero()[0]\n",
    "    col = train.nonzero()[1]\n",
    "    size = train.shape\n",
    "    train = csr_matrix((data,(row,col)),shape = size)\n",
    "\n",
    "    mult = train.multiply(test)\n",
    "    assert(mult.nnz == 0)\n",
    "    \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rating_matrix(city_review_data):\n",
    "    unique_users = city_review_data['user_id'].unique().tolist()\n",
    "    unique_rests = city_review_data['business_id'].unique().tolist()\n",
    "    num_user = len(unique_users)\n",
    "    num_rest = len(unique_rests)\n",
    "\n",
    "    print \"Number of Users: {}\".format(num_user)\n",
    "    print \"Number of Restaurent: {}\".format(num_rest)\n",
    "    \n",
    "    train, test = split_train_test(city_review_data)\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sparsity of rating matrix\n",
    "def get_sparsity(rating_matrix):\n",
    "    total_filled_values = rating_matrix.nnz\n",
    "    return 1 - float(total_filled_values)/float(rating_matrix.shape[0]*rating_matrix.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the review data\n",
    "eider.env.getUploaded(\"15core.csv\", \"/tmp/15core.csv\")\n",
    "review_data = read_review_data('/tmp/15core.csv')\n",
    "print '-----------------------------'\n",
    "print 'Filtering the Restaurant data'\n",
    "print '-----------------------------'\n",
    "restaurant_reviews = get_restaurant_data(review_data, business_data)\n",
    "print restaurant_reviews.head(3)\n",
    "print '-----------------------------'\n",
    "print 'restaurant reviews top 10 cities'\n",
    "print '-----------------------------'\n",
    "print restaurant_reviews['city'].value_counts().head(10)\n",
    "print '-----------------------------'\n",
    "vegas_40 = get_city_restaurant_data('Las Vegas', restaurant_reviews)\n",
    "vegas_40_train, vegas_40_test = get_rating_matrix(vegas_40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "print vegas_40_train.shape\n",
    "print vegas_40_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "print get_sparsity(vegas_40_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_missing_with_mean(matrix):\n",
    "    dense = matrix.toarray()\n",
    "    ndf = pd.DataFrame(dense)\n",
    "    ndf = ndf.replace(to_replace = 0, value = np.nan)\n",
    "    ndf = ndf.fillna(ndf.mean())\n",
    "    return ndf.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import scale\n",
    "vegas_40_mean_filled = fill_missing_with_mean(vegas_40_train)\n",
    "mean_centered = scale(vegas_40_mean_filled, axis = 1, with_std=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "transpose = mean_centered.transpose()\n",
    "item_similarity = np.matmul(transpose, mean_centered)\n",
    "item_similarity.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "U, S, V = np.linalg.svd(item_similarity)\n",
    "print(\"smallest singular value = \",min(S))\n",
    "print(\"largest singular value = \",max(S))\n",
    "S_diag = np.diag(S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "print U.shape\n",
    "print S.shape\n",
    "print V.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,5))\n",
    "plt.semilogy(S[:200], '-', linewidth=1)\n",
    "plt.title('Elbow Plot')\n",
    "plt.xlabel('Principal Component')\n",
    "plt.ylabel('Singular Values')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "projection = U[:,:50]\n",
    "low_dim_rating_projection = np.matmul(mean_centered, projection)\n",
    "low_dim_rating_projection.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "N = low_dim_rating_projection.shape[0]\n",
    "out = [[0 for i in range(N)] for j in range(N)]\n",
    "for i in range(N):\n",
    "    out[i] = [pearsonr(low_dim_rating_projection[i],low_dim_rating_projection[j])[0] for j in range(N)]\n",
    "print out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_100_similar_users = []\n",
    "for j in range(len(out)):\n",
    "    top_100_similar_users.append(sorted(range(len(out[j])), key=lambda i: out[j][i], reverse = True)[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense =vegas_40_train.toarray()\n",
    "ndf = pd.DataFrame(dense)\n",
    "ndf = ndf.replace(to_replace = 0, value = np.nan)\n",
    "ndf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = ndf.values\n",
    "train = ndf.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_rating(row, col):\n",
    "    neighbors = top_100_similar_users[row]\n",
    "    ls = []\n",
    "    for n in neighbors:\n",
    "        if np.isnan(train[n, col]):\n",
    "            continue\n",
    "        else:\n",
    "            ls.append(float(arr[n,col]) * float(out[row][n]))\n",
    "    if len(ls) == 0:\n",
    "        return 0\n",
    "    return float(sum(ls))/len(ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ndf.columns:\n",
    "    for item in ndf[col].iteritems():\n",
    "        row = item[0]\n",
    "        val = item[1]\n",
    "        if pd.isnull(val):\n",
    "            arr[row, col] = predict_rating(row, col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame(arr)\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# These are the usual ipython objects, including this one you are creating\n",
    "ipython_vars = ['In', 'Out', 'exit', 'quit', 'get_ipython', 'ipython_vars']\n",
    "\n",
    "# Get a sorted list of the objects and their sizes\n",
    "sorted([(x, sys.getsizeof(globals().get(x))) for x in dir() if not x.startswith('_') and x not in sys.modules and x not in ipython_vars], key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "del business_data\n",
    "del review_data\n",
    "del restaurant_reviews\n",
    "\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame(vegas_40_test.todense())\n",
    "test_df = test_df.replace(to_replace = 0, value = np.nan)\n",
    "test_df_mask = ((test_df.notnull()).astype('int'))\n",
    "test_df_mask.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "def get_mse(pred, actual):\n",
    "    # Ignore zero terms.\n",
    "    pred = pred[actual.nonzero()].flatten()\n",
    "    print len(pred)\n",
    "    actual = actual[actual.nonzero()].flatten()\n",
    "    print len(actual)\n",
    "    return mean_absolute_error(pred, actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_result = np.multiply(test_df_mask.values, result.values)\n",
    "actual = test_df.replace(to_replace = np.nan, value = 0).values\n",
    "actual = np.multiply(actual, test_df_mask.values)\n",
    "get_mse(mask_result, actual)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
